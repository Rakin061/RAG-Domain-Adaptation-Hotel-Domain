{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3UmoA6ziDAA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717560895561,"user_tz":-360,"elapsed":19561,"user":{"displayName":"Z Khan","userId":"14906502170561123541"}},"outputId":"04efc179-8651-404e-e9a7-61057d97b71a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain==0.1.19\n","  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openai==0.28.0\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.19)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.19)\n","  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.19)\n","  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.19)\n","  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n","  Downloading langsmith-0.1.71-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.66.4)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n","  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, tiktoken, marshmallow, jsonpatch, openai, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.71 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-0.28.0 orjson-3.10.3 packaging-23.2 tiktoken-0.7.0 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain==0.1.19 \\\n","              openai==0.28.0 \\\n","              tiktoken"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1937,"status":"ok","timestamp":1716092026107,"user":{"displayName":"Z Khan","userId":"14906502170561123541"},"user_tz":-360},"id":"LFYxDkV5DSD8","outputId":"079eef03-9e4e-4a26-f0e0-e63d761ad20f"},"outputs":[{"name":"stdout","output_type":"stream","text":["langchain                        0.2.0\n","langchain-core                   0.2.0\n","langchain-text-splitters         0.2.0\n"]}],"source":["!pip list | grep langchain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDsUCj65DRU3"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","from google.colab import userdata\n","import openai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hgOAI1wMJaA"},"outputs":[],"source":["hotel_services = [\n","  # \"Room service - Food\",\n","  # \"Hotel Restaurants\",\n","  # \"Bill query\",\n","  # \"Security Concern\",\n","  # \"Facilities Availability\",\n","  # \"Housekeeping\",\n","  # \"Room maintenance\",\n","  # \"Room amenities\",\n","  # \"Minibar\",\n","  # \"Wakeup Call\",\n","  # \"Emergency Alert\",\n","  # \"Query on hotel policy\",\n","  # \"Review/ Feedback\",\n","  # \"Concierge Service\",\n","  # \"Contacts\",\n","  # \"Transportation\",\n","  # \"Spa and wellness\",\n","  # \"Parking\",\n","  # \"Noise Complaint\",\n","  # \"Lost Room Key\",\n","  # \"Request for Late Check-Out / Early Check-in\",\n","  # \"Request for Room Change\",\n","  # \"Pickup laundry\",\n","  # \"Pickup package delivery\",\n","  \"Miscellaneous:TV\",\n","  \"Miscellaneous:AC\",\n","  \"Miscellaneous:WiFi\",\n","  \"Miscellaneous:Shower\",\n","  \"Miscellaneous:Lights\",\n","  \"Miscellaneous:Sink\",\n","  \"Miscellaneous:Lamp\",\n","  \"Miscellaneous:Curtains\",\n","  # \"Miscellaneous:Minibar\"\n","]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":581,"status":"ok","timestamp":1717560982314,"user":{"displayName":"Z Khan","userId":"14906502170561123541"},"user_tz":-360},"id":"E-XrO1ZzOmLo","outputId":"afa7e0a5-ba5f-4629-d131-ab6e4bde95fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":6}],"source":["len(hotel_services)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2186,"status":"ok","timestamp":1717561001543,"user":{"displayName":"Z Khan","userId":"14906502170561123541"},"user_tz":-360},"id":"uuVZEbkyMigo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"336848d9-645d-4f03-f318-e95f7ff2a8eb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n","  warn_deprecated(\n"]}],"source":["from langchain.chat_models import ChatOpenAI\n","from google.colab import userdata\n","\n","chat = ChatOpenAI(\n","    openai_api_key=userdata.get(\"OpenAI_API_KEY\"),\n","    model='gpt-3.5-turbo'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ebw5jISMlqw"},"outputs":[],"source":["from langchain.schema import (\n","    SystemMessage,\n","    HumanMessage,\n","    AIMessage\n",")\n","\n","messages = [\n","    SystemMessage(content=\"You are a helpful assistant who will generate real life conversation between a user and a hotel assistant\"),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BXmkn1UM6aZ"},"outputs":[],"source":["def augment_prompt_for_conversation(category: str):\n","    # get top 3 results from knowledge base\n","    # get the text from the results\n","    # feed into an augmented prompt\n","    augmented_prompt = f\"\"\" Generate Conversations between an \"User\" and a \"Hotel Assistant\" on this category: \"{category}\".\n","                            \"\"\"\n","    return augmented_prompt"]},{"cell_type":"code","source":["import csv\n","import random\n","import datetime\n","\n","# Function to generate a random timestamp\n","def generate_random_timestamp():\n","    # Generate a random date\n","    start_date = datetime.date(2010, 1, 1)\n","    end_date = datetime.date(2024, 5, 31)\n","    random_date = start_date + datetime.timedelta(days=random.randint(0, (end_date - start_date).days))\n","\n","    # Generate a random time\n","    random_time = datetime.time(random.randint(0, 23), random.randint(0, 59))\n","\n","    # Combine date and time to a datetime object and format it\n","    random_datetime = datetime.datetime.combine(random_date, random_time)\n","    return random_datetime.strftime('%Y%m%d_%H%M')\n","\n","# Function to save conversation to a CSV file\n","def save_conversation_to_csv(title, text):\n","    with open('ConversationFromCategory2.csv', 'a', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow([title,text])\n"],"metadata":{"id":"_7EEvevAuP2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","# write header in the csv\n","with open('ConversationFromCategory2.csv', 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['title','text'])"],"metadata":{"id":"QJ9kihLOvE6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# category = \"Security Concern\"\n","for c in range(len(hotel_services)):\n","  category = hotel_services[c]\n","  print(category)\n","  for i in range(70):\n","    prompt = augment_prompt_for_conversation(category)\n","    # Create a HumanMessage object with the augmented prompt\n","    prompt = HumanMessage(content=prompt)\n","\n","    res = chat([prompt])\n","    print(i)\n","\n","    timestamp = generate_random_timestamp()\n","    title = category + \"_\" + timestamp\n","    save_conversation_to_csv(title, res.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"c2Qa7ERBnNK_","executionInfo":{"status":"ok","timestamp":1717562747407,"user_tz":-360,"elapsed":1669475,"user":{"displayName":"Z Khan","userId":"14906502170561123541"}},"outputId":"f0c7b54d-791e-4b5b-b39f-3370a291cae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Miscellaneous:TV\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:AC\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:WiFi\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:Shower\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:Lights\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:Sink\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:Lamp\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","Miscellaneous:Curtains\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac9BOiScSnoY"},"outputs":[],"source":["import csv\n","with open('TestConversations_review_16106.csv', 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['title','text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qI0D8-FUk0_"},"outputs":[],"source":["with open('tripadvisor-hotel-reviews_dataset-train.csv', 'r', newline='') as tripadvisor_file:\n","    tripadvisor_reader = csv.DictReader(tripadvisor_file)\n","    # Open the TestConversations_review.csv file in append mode\n","    with open('TestConversations_review_16106.csv', 'a', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        # Iterate through each row in the TripAdvisor dataset\n","        for row in tripadvisor_reader:\n","            # Get the text from the 'text' column\n","            text = row['text']\n","            # Augment the prompt using the function\n","            prompt = augment_prompt_for_conversation(text)\n","            # Create a HumanMessage object with the augmented prompt\n","            prompt = HumanMessage(content=prompt)\n","\n","            res = chat([prompt])\n","            # Split the response into separate conversation parts\n","            # conversation = res.content.split(\"<end>\")\n","            # Write each conversation part to the CSV file along with the hotel service\n","            # for part in conversation:\n","            #     writer.writerow([part, row['hotel_service']])\n","            print (row['id'])\n","            writer.writerow([f\"{row['id']}\", res.content])\n","        print(\"Done\")\n","\n","# with open('tripadvisor-hotel-reviews_dataset-train.csv', 'r', newline='') as tripadvisor_file:\n","#     tripadvisor_reader = csv.DictReader(tripadvisor_file)\n","#     prompt = HumanMessage(content=augment_prompt_for_conversation(hotel_services[i]))\n","#     res = chat([prompt])\n","\n","#     with open('TestConversations_review.csv', 'a', newline='') as csvfile:\n","#         writer = csv.writer(csvfile)\n","#         for i in range(len(hotel_services)):\n","#             conversation = res.content.split(\"<end>\")\n","#             for j in range(len(conversation)-1):\n","#               writer.writerow([f\"{hotel_services[i]}\", conversation[j]])\n","#             print(i)\n","#     print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRFWOnSWkN2I"},"outputs":[],"source":["!pip install datasets\n","from datasets import load_dataset\n","\n","# Load the dataset\n","dataset = load_dataset(\"argilla/tripadvisor-hotel-reviews\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEe1tQ3Kl0iY"},"outputs":[],"source":["from datasets import load_dataset\n","\n","from datasets import load_from_disk\n","\n","raw_datasets = load_dataset(\"argilla/tripadvisor-hotel-reviews\")\n","raw_datasets.cache_files\n","\n","raw_datasets.save_to_disk(\"tripadvisor-hotel-reviews-arrow-datasets\")\n","\n","\n","arrow_datasets_reloaded = load_from_disk(\"tripadvisor-hotel-reviews-arrow-datasets\")\n","arrow_datasets_reloaded\n","\n","for split, dataset in raw_datasets.items():\n","    dataset.to_csv(f\"tripadvisor-hotel-reviews_dataset-{split}.csv\", index=None)\n","\n","\n","for split, dataset in raw_datasets.items():\n","    dataset.to_json(f\"tripadvisor-hotel-reviews_dataset-{split}.jsonl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrmh4VoUkTQQ"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6UXP5W2O72WeIiY7GOfhf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}